[{"trial": 0, "search_space": "{'params': {'ccp_alpha': 0.002, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.7246685606060606, "Precision": 0.5661789021164021, "AUC": 0.9939396923128923, "Accuracy": 0.998870352128544, "Recall_Std": 0.09756402038253459, "Precision_Std": 0.11893184353936705, "AUC_Std": 0.007058052105786052, "Accuracy_Std": 0.00042259446126078807, "F1-Score": 0.6302922916082608}}, {"trial": 1, "search_space": "{'params': {'ccp_alpha': 0.084, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.021368082861764885, "AUC": 0.9859883030001544, "Accuracy": 0.9462773904538162, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.003668053584436296, "AUC_Std": 0.007135929716454388, "Accuracy_Std": 0.013924502808585164, "F1-Score": 0.04166028095763158}}, {"trial": 2, "search_space": "{'params': {'ccp_alpha': 0.011, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8091856060606061, "Precision": 0.16471026237800251, "AUC": 0.9965398505963924, "Accuracy": 0.9941356371143162, "Recall_Std": 0.13093803796425033, "Precision_Std": 0.048586923777710435, "AUC_Std": 0.0024564287006529194, "Accuracy_Std": 0.0014175301850121694, "F1-Score": 0.2720868645559602}}, {"trial": 3, "search_space": "{'params': {'ccp_alpha': 0.063, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.025591884740697818, "AUC": 0.9889309101416748, "Accuracy": 0.9572007684707754, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0009785441525040231, "AUC_Std": 0.006020517221131776, "Accuracy_Std": 0.004080566634758648, "F1-Score": 0.04970997440308805}}, {"trial": 4, "search_space": "{'params': {'ccp_alpha': 0.03, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8705018939393939, "Precision": 0.05579226435457809, "AUC": 0.9936903938789183, "Accuracy": 0.9797252245329232, "Recall_Std": 0.10334423740219516, "Precision_Std": 0.014380138383739699, "AUC_Std": 0.004716749026874115, "Accuracy_Std": 0.004742196678240964, "F1-Score": 0.1046840287274314}}, {"trial": 5, "search_space": "{'params': {'ccp_alpha': 0.073, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.023692193428498036, "AUC": 0.9867832334326954, "Accuracy": 0.9533500820058792, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0016320889693417111, "AUC_Std": 0.007091481952150269, "Accuracy_Std": 0.006565559987487099, "F1-Score": 0.04610584445856223}}, {"trial": 6, "search_space": "{'params': {'ccp_alpha': 0.074, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.023859625224050524, "AUC": 0.9867706981123427, "Accuracy": 0.9535268992946807, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.002052938676444258, "AUC_Std": 0.006902195549272514, "Accuracy_Std": 0.007214379939425837, "F1-Score": 0.046419258078694854}}, {"trial": 7, "search_space": "{'params': {'ccp_alpha': 0.047, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.029691062691534587, "AUC": 0.9913576583630578, "Accuracy": 0.9631143128839816, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.00346005548314166, "AUC_Std": 0.0051466606720028864, "Accuracy_Std": 0.002335558408530364, "F1-Score": 0.05741359692948246}}, {"trial": 8, "search_space": "{'params': {'ccp_alpha': 0.003, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.7402935606060606, "Precision": 0.47574437757364585, "AUC": 0.9937328759725482, "Accuracy": 0.9984676105145686, "Recall_Std": 0.09007263696186668, "Precision_Std": 0.13550764505059915, "AUC_Std": 0.006941122740701568, "Accuracy_Std": 0.0007212730304525078, "F1-Score": 0.5731115731115731}}, {"trial": 9, "search_space": "{'params': {'ccp_alpha': 0.093, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.0211485109856506, "AUC": 0.9856691597845446, "Accuracy": 0.9457862313182563, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.003636137600937856, "AUC_Std": 0.006907980211632845, "Accuracy_Std": 0.013671777345763678, "F1-Score": 0.04124225511958443}}, {"trial": 10, "search_space": "{'params': {'ccp_alpha': 0.006, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.7632575757575758, "Precision": 0.2688041125541126, "AUC": 0.9932630136811583, "Accuracy": 0.9968271602298465, "Recall_Std": 0.10155118650344326, "Precision_Std": 0.07111774719801305, "AUC_Std": 0.007455710824628215, "Accuracy_Std": 0.0010140865715787353, "F1-Score": 0.39582538673447765}}, {"trial": 11, "search_space": "{'params': {'ccp_alpha': 0.088, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.02114462225015072, "AUC": 0.9854131406665783, "Accuracy": 0.945766584952834, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.003642411695189141, "AUC_Std": 0.00741125947510895, "Accuracy_Std": 0.013703192084624867, "F1-Score": 0.0412347325669717}}, {"trial": 12, "search_space": "{'params': {'ccp_alpha': 0.034, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8705018939393939, "Precision": 0.04825908640444844, "AUC": 0.9933047099369565, "Accuracy": 0.976316630693488, "Recall_Std": 0.10334423740219516, "Precision_Std": 0.012724657478529494, "AUC_Std": 0.004927156771900762, "Accuracy_Std": 0.005688736997237504, "F1-Score": 0.09130836262236414}}, {"trial": 13, "search_space": "{'params': {'ccp_alpha': 0.069, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.024435002759393296, "AUC": 0.9880415442073146, "Accuracy": 0.9548530289606926, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0016428718085341363, "AUC_Std": 0.006200614978185572, "Accuracy_Std": 0.006041481605869794, "F1-Score": 0.047514093464727035}}, {"trial": 14, "search_space": "{'params': {'ccp_alpha': 0.053, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.02861189216011397, "AUC": 0.9899991949949856, "Accuracy": 0.9618274852119628, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0027251146465863143, "AUC_Std": 0.00608427346923529, "Accuracy_Std": 0.0012029838748292302, "F1-Score": 0.0553999058444277}}, {"trial": 15, "search_space": "{'params': {'ccp_alpha': 0.019, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8551136363636364, "Precision": 0.09950925609153456, "AUC": 0.9955441246460489, "Accuracy": 0.9896268209516048, "Recall_Std": 0.11396338676906333, "Precision_Std": 0.02034192193226432, "AUC_Std": 0.0032674378417559672, "Accuracy_Std": 0.0015941424675376082, "F1-Score": 0.1777995526500134}}, {"trial": 16, "search_space": "{'params': {'ccp_alpha': 0.068, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.024476647701281946, "AUC": 0.9882045823075601, "Accuracy": 0.9549512607878046, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0015887261218604373, "AUC_Std": 0.0062855164285463136, "Accuracy_Std": 0.005933660251090298, "F1-Score": 0.04759343335682478}}, {"trial": 17, "search_space": "{'params': {'ccp_alpha': 0.057, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.02742217778824772, "AUC": 0.9892930752145106, "Accuracy": 0.9600887853457614, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0022200314722632575, "AUC_Std": 0.006517520307394665, "Accuracy_Std": 0.0030812742087741917, "F1-Score": 0.05316054726770288}}, {"trial": 18, "search_space": "{'params': {'ccp_alpha': 0.097, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.0211485109856506, "AUC": 0.9854467701841183, "Accuracy": 0.9457862313182563, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.003636137600937856, "AUC_Std": 0.007127008929562589, "Accuracy_Std": 0.013671777345763678, "F1-Score": 0.04124225511958443}}, {"trial": 19, "search_space": "{'params': {'ccp_alpha': 0.019, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8551136363636364, "Precision": 0.09950925609153456, "AUC": 0.9955441246460489, "Accuracy": 0.9896268209516048, "Recall_Std": 0.11396338676906333, "Precision_Std": 0.02034192193226432, "AUC_Std": 0.0032674378417559672, "Accuracy_Std": 0.0015941424675376082, "F1-Score": 0.1777995526500134}}, {"trial": 20, "search_space": "{'params': {'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.6711647727272727, "Precision": 0.8888167184007592, "AUC": 0.9833328514216886, "Accuracy": 0.9994695550809565, "Recall_Std": 0.1218749908025473, "Precision_Std": 0.0243144883492399, "AUC_Std": 0.015751198479472976, "Accuracy_Std": 0.0001402943573615322, "F1-Score": 0.7586582977207977}}, {"trial": 21, "search_space": "{'params': {'ccp_alpha': 0.004, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.7554450757575758, "Precision": 0.4102633477633478, "AUC": 0.9936840922899306, "Accuracy": 0.9980157526010727, "Recall_Std": 0.10345481414713979, "Precision_Std": 0.1493927690762284, "AUC_Std": 0.007177058264944705, "Accuracy_Std": 0.001008817426703554, "F1-Score": 0.5231765493278651}}, {"trial": 22, "search_space": "{'params': {'ccp_alpha': 0.002, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.7246685606060606, "Precision": 0.5661789021164021, "AUC": 0.9939396923128923, "Accuracy": 0.998870352128544, "Recall_Std": 0.09756402038253459, "Precision_Std": 0.11893184353936705, "AUC_Std": 0.007058052105786052, "Accuracy_Std": 0.00042259446126078807, "F1-Score": 0.6302922916082608}}, {"trial": 23, "search_space": "{'params': {'ccp_alpha': 0.091, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.021252344436794968, "AUC": 0.985472663412279, "Accuracy": 0.9460416340687474, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0036346994537903746, "AUC_Std": 0.007108096146389778, "Accuracy_Std": 0.013727808656716349, "F1-Score": 0.04144023539443979}}, {"trial": 24, "search_space": "{'params': {'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.6711647727272727, "Precision": 0.8888167184007592, "AUC": 0.9833328514216886, "Accuracy": 0.9994695550809565, "Recall_Std": 0.1218749908025473, "Precision_Std": 0.0243144883492399, "AUC_Std": 0.015751198479472976, "Accuracy_Std": 0.0001402943573615322, "F1-Score": 0.7586582977207977}}, {"trial": 25, "search_space": "{'params': {'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.6711647727272727, "Precision": 0.8888167184007592, "AUC": 0.9833328514216886, "Accuracy": 0.9994695550809565, "Recall_Std": 0.1218749908025473, "Precision_Std": 0.0243144883492399, "AUC_Std": 0.015751198479472976, "Accuracy_Std": 0.0001402943573615322, "F1-Score": 0.7586582977207977}}, {"trial": 26, "search_space": "{'params': {'ccp_alpha': 0.018, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8551136363636364, "Precision": 0.10327458467460664, "AUC": 0.9957219478504052, "Accuracy": 0.9901179789292711, "Recall_Std": 0.11396338676906333, "Precision_Std": 0.018942858688274375, "AUC_Std": 0.003091203579750203, "Accuracy_Std": 0.0012092980650763286, "F1-Score": 0.1839842404910351}}, {"trial": 27, "search_space": "{'params': {'ccp_alpha': 0.02, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8626893939393939, "Precision": 0.09538650302007959, "AUC": 0.9954190470842179, "Accuracy": 0.9889981434335202, "Recall_Std": 0.10151144130488102, "Precision_Std": 0.01993305972272446, "AUC_Std": 0.003436118428444781, "Accuracy_Std": 0.0018327016017033444, "F1-Score": 0.17126634854709308}}, {"trial": 28, "search_space": "{'params': {'ccp_alpha': 0.036, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.04319621086592304, "AUC": 0.9928061945413972, "Accuracy": 0.9738313770464899, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.009946566898678991, "AUC_Std": 0.005261337421019295, "Accuracy_Std": 0.005482499615114324, "F1-Score": 0.0821943420437358}}, {"trial": 29, "search_space": "{'params': {'ccp_alpha': 0.022, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8705018939393939, "Precision": 0.08710676267810682, "AUC": 0.9949258240508084, "Accuracy": 0.9877015010700094, "Recall_Std": 0.10334423740219516, "Precision_Std": 0.019661693441353344, "AUC_Std": 0.0037899202167635576, "Accuracy_Std": 0.002144755758193534, "F1-Score": 0.15786827048751495}}, {"trial": 30, "search_space": "{'params': {'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.6711647727272727, "Precision": 0.8888167184007592, "AUC": 0.9833328514216886, "Accuracy": 0.9994695550809565, "Recall_Std": 0.1218749908025473, "Precision_Std": 0.0243144883492399, "AUC_Std": 0.015751198479472976, "Accuracy_Std": 0.0001402943573615322, "F1-Score": 0.7586582977207977}}, {"trial": 31, "search_space": "{'params': {'ccp_alpha': 0.015, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8551136363636364, "Precision": 0.1233109980834439, "AUC": 0.9959928143865048, "Accuracy": 0.9919156082426273, "Recall_Std": 0.11396338676906333, "Precision_Std": 0.02054111044338272, "AUC_Std": 0.002854380729078114, "Accuracy_Std": 0.0008106050846983412, "F1-Score": 0.21535134462714461}}, {"trial": 32, "search_space": "{'params': {'ccp_alpha': 0.001, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.7168560606060606, "Precision": 0.7404040404040404, "AUC": 0.986737862364916, "Accuracy": 0.9993025640625821, "Recall_Std": 0.10378286733090064, "Precision_Std": 0.08741605794716285, "AUC_Std": 0.013258955152714379, "Accuracy_Std": 0.00020105935726524095, "F1-Score": 0.724374730129206}}, {"trial": 33, "search_space": "{'params': {'ccp_alpha': 0.027, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8705018939393939, "Precision": 0.0655692332771193, "AUC": 0.9940389278405863, "Accuracy": 0.9835463468883812, "Recall_Std": 0.10334423740219516, "Precision_Std": 0.011976660108640498, "AUC_Std": 0.004487668923684029, "Accuracy_Std": 0.002346833774214365, "F1-Score": 0.12181537523336473}}, {"trial": 34, "search_space": "{'params': {'ccp_alpha': 0.005, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.7632575757575758, "Precision": 0.34093045112781956, "AUC": 0.9935185834462766, "Accuracy": 0.9974951320226338, "Recall_Std": 0.10155118650344326, "Precision_Std": 0.11403818070353068, "AUC_Std": 0.007252887943761921, "Accuracy_Std": 0.0011580216225574528, "F1-Score": 0.4654570087030052}}, {"trial": 35, "search_space": "{'params': {'ccp_alpha': 0.071, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.024296260482225135, "AUC": 0.987805057971594, "Accuracy": 0.9546074493929125, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.001544451711413153, "AUC_Std": 0.006231843237371602, "Accuracy_Std": 0.006010583843001429, "F1-Score": 0.04725196506518982}}, {"trial": 36, "search_space": "{'params': {'ccp_alpha': 0.025, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8705018939393939, "Precision": 0.0717874523888595, "AUC": 0.9942305485368717, "Accuracy": 0.9850689185946044, "Recall_Std": 0.10334423740219516, "Precision_Std": 0.013043272099537075, "AUC_Std": 0.00441499496355127, "Accuracy_Std": 0.0021162705664942946, "F1-Score": 0.13245209444845263}}, {"trial": 37, "search_space": "{'params': {'ccp_alpha': 0.081, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.02139727483358178, "AUC": 0.9862812315677798, "Accuracy": 0.946365799098217, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.003658206279072934, "AUC_Std": 0.00695766029527808, "Accuracy_Std": 0.013876285560084928, "F1-Score": 0.04171608745173748}}, {"trial": 38, "search_space": "{'params': {'ccp_alpha': 0.043, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.03149211094433088, "AUC": 0.9917155461529139, "Accuracy": 0.9650985946337503, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.004264270787603589, "AUC_Std": 0.005135737441863828, "Accuracy_Std": 0.0033242978826608463, "F1-Score": 0.060767487890815326}}, {"trial": 39, "search_space": "{'params': {'ccp_alpha': 0.014, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8551136363636364, "Precision": 0.12917209010530264, "AUC": 0.9961067533931135, "Accuracy": 0.9922692408904077, "Recall_Std": 0.11396338676906333, "Precision_Std": 0.024752819530013032, "AUC_Std": 0.002753454348760674, "Accuracy_Std": 0.0009740931807066993, "F1-Score": 0.22409338651114968}}, {"trial": 40, "search_space": "{'params': {'ccp_alpha': 0.078, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.022475306091618005, "AUC": 0.9864710908805807, "Accuracy": 0.9484483138329911, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.004232382126378794, "AUC_Std": 0.00681002008852405, "Accuracy_Std": 0.01488120781611544, "F1-Score": 0.043758432896255015}}, {"trial": 41, "search_space": "{'params': {'ccp_alpha': 0.098, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.0211485109856506, "AUC": 0.9854512501907279, "Accuracy": 0.9457862313182563, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.003636137600937856, "AUC_Std": 0.0071201365659206125, "Accuracy_Std": 0.013671777345763678, "F1-Score": 0.04124225511958443}}, {"trial": 42, "search_space": "{'params': {'ccp_alpha': 0.029, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8705018939393939, "Precision": 0.05760352542992238, "AUC": 0.9937806857072194, "Accuracy": 0.9804717729102164, "Recall_Std": 0.10334423740219516, "Precision_Std": 0.014515453899950622, "AUC_Std": 0.004685742883249189, "Accuracy_Std": 0.004392561155840165, "F1-Score": 0.10787759722557702}}, {"trial": 43, "search_space": "{'params': {'ccp_alpha': 0.052, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.028973165908128398, "AUC": 0.9901762838499739, "Accuracy": 0.9622400588858332, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.003137225217209842, "AUC_Std": 0.006004352476465496, "Accuracy_Std": 0.0018351793030414371, "F1-Score": 0.05607395639607924}}, {"trial": 44, "search_space": "{'params': {'ccp_alpha': 0.033, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8705018939393939, "Precision": 0.05014857394536539, "AUC": 0.99333765429579, "Accuracy": 0.9770828366291743, "Recall_Std": 0.10334423740219516, "Precision_Std": 0.013587431631010415, "AUC_Std": 0.004941339440111096, "Accuracy_Std": 0.005937179648560428, "F1-Score": 0.09467066278476824}}, {"trial": 45, "search_space": "{'params': {'ccp_alpha': 0.094, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.0211485109856506, "AUC": 0.9856977443506001, "Accuracy": 0.9457862313182563, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.003636137600937856, "AUC_Std": 0.0068788433825997565, "Accuracy_Std": 0.013671777345763678, "F1-Score": 0.04124225511958443}}, {"trial": 46, "search_space": "{'params': {'ccp_alpha': 0.032, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8705018939393939, "Precision": 0.05285150986268014, "AUC": 0.9934348039614483, "Accuracy": 0.9780847958622134, "Recall_Std": 0.10334423740219516, "Precision_Std": 0.014933677982779087, "AUC_Std": 0.004882165554731224, "Accuracy_Std": 0.0061889435162386765, "F1-Score": 0.09944591728336626}}, {"trial": 47, "search_space": "{'params': {'ccp_alpha': 0.044, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.030760215127311835, "AUC": 0.9915990100269028, "Accuracy": 0.9642243321443826, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.00444739412843241, "AUC_Std": 0.0051643310595202736, "Accuracy_Std": 0.003254820495671259, "F1-Score": 0.05940013470239489}}, {"trial": 48, "search_space": "{'params': {'ccp_alpha': 0.066, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.0249315304348297, "AUC": 0.9884744338440088, "Accuracy": 0.9559335790589244, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0012231143886902436, "AUC_Std": 0.006170660481695306, "Accuracy_Std": 0.004991111108982439, "F1-Score": 0.04845844587835133}}, {"trial": 49, "search_space": "{'params': {'ccp_alpha': 0.021, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8626893939393939, "Precision": 0.09068393205632669, "AUC": 0.9951511627297349, "Accuracy": 0.9883400029286986, "Recall_Std": 0.10151144130488102, "Precision_Std": 0.020273619048106265, "AUC_Std": 0.003629769064600052, "Accuracy_Std": 0.0019421453688738142, "F1-Score": 0.163633605188871}}, {"trial": 50, "search_space": "{'params': {'ccp_alpha': 0.056, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.027482617674353265, "AUC": 0.9893649757698204, "Accuracy": 0.9601575476247397, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0023374882605816656, "AUC_Std": 0.0065180013135712, "Accuracy_Std": 0.0031890666108761365, "F1-Score": 0.05327335542022294}}, {"trial": 51, "search_space": "{'params': {'ccp_alpha': 0.013, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8475378787878788, "Precision": 0.14553799814499443, "AUC": 0.9963085230833109, "Accuracy": 0.9931238546985659, "Recall_Std": 0.11109451996768484, "Precision_Std": 0.036471451706554366, "AUC_Std": 0.002600753879499154, "Accuracy_Std": 0.0013309371064641497, "F1-Score": 0.24738192493681083}}, {"trial": 52, "search_space": "{'params': {'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.6711647727272727, "Precision": 0.8888167184007592, "AUC": 0.9833328514216886, "Accuracy": 0.9994695550809565, "Recall_Std": 0.1218749908025473, "Precision_Std": 0.0243144883492399, "AUC_Std": 0.015751198479472976, "Accuracy_Std": 0.0001402943573615322, "F1-Score": 0.7586582977207977}}, {"trial": 53, "search_space": "{'params': {'ccp_alpha': 0.076, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.0227222769960565, "AUC": 0.986409256599961, "Accuracy": 0.9496074493929125, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0038234988550999755, "AUC_Std": 0.006849544175072998, "Accuracy_Std": 0.013005189181766184, "F1-Score": 0.04423553876255454}}, {"trial": 54, "search_space": "{'params': {'ccp_alpha': 0.008, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.7940340909090909, "Precision": 0.21556829081536932, "AUC": 0.9967496017175984, "Accuracy": 0.9957957380100704, "Recall_Std": 0.11388368761079784, "Precision_Std": 0.055037956695632224, "AUC_Std": 0.002278259684138068, "Accuracy_Std": 0.001143107753628138, "F1-Score": 0.3378359669492219}}, {"trial": 55, "search_space": "{'params': {'ccp_alpha': 0.089, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.021140068904864858, "AUC": 0.9854021122724643, "Accuracy": 0.9457567617701228, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0036386601269799788, "AUC_Std": 0.007383303139904048, "Accuracy_Std": 0.013700773288390528, "F1-Score": 0.04122606293312285}}, {"trial": 56, "search_space": "{'params': {'ccp_alpha': 0.092, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.0211485109856506, "AUC": 0.9855421358966769, "Accuracy": 0.9457862313182563, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.003636137600937856, "AUC_Std": 0.00701217383591595, "Accuracy_Std": 0.013671777345763678, "F1-Score": 0.04124225511958443}}, {"trial": 57, "search_space": "{'params': {'ccp_alpha': 0.064, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.0250519128788489, "AUC": 0.9885331607539382, "Accuracy": 0.9561693342860995, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0011406124719209937, "AUC_Std": 0.006212422128515357, "Accuracy_Std": 0.0048613499814290665, "F1-Score": 0.04868645008053884}}, {"trial": 58, "search_space": "{'params': {'ccp_alpha': 0.039, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.03600845782463151, "AUC": 0.9923070946147708, "Accuracy": 0.9692046761298475, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.00646467836374554, "AUC_Std": 0.0050110693506366915, "Accuracy_Std": 0.004175911063048138, "F1-Score": 0.06911663602778681}}, {"trial": 59, "search_space": "{'params': {'ccp_alpha': 0.009, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.7940340909090909, "Precision": 0.19171725201136963, "AUC": 0.996622744625126, "Accuracy": 0.9952259961145724, "Recall_Std": 0.11388368761079784, "Precision_Std": 0.048080848228091416, "AUC_Std": 0.0023148400311247827, "Accuracy_Std": 0.0010646206554106251, "F1-Score": 0.3077188117637455}}, {"trial": 60, "search_space": "{'params': {'ccp_alpha': 0.096, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.0211485109856506, "AUC": 0.9854762768329497, "Accuracy": 0.9457862313182563, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.003636137600937856, "AUC_Std": 0.007105460162623039, "Accuracy_Std": 0.013671777345763678, "F1-Score": 0.04124225511958443}}, {"trial": 61, "search_space": "{'params': {'ccp_alpha': 0.099, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.02114395764036474, "AUC": 0.9855415589349263, "Accuracy": 0.9457764081355452, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0036323844274647396, "AUC_Std": 0.0070837470786638, "Accuracy_Std": 0.013669367109107905, "F1-Score": 0.04123358548573558}}, {"trial": 62, "search_space": "{'params': {'ccp_alpha': 0.072, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.023939475153459237, "AUC": 0.9877344563160476, "Accuracy": 0.953792125227883, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0018199909115857009, "AUC_Std": 0.0062274384316797675, "Accuracy_Std": 0.006711163356398364, "F1-Score": 0.04657328435194865}}, {"trial": 63, "search_space": "{'params': {'ccp_alpha': 0.01, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8016098484848485, "Precision": 0.17475152990238255, "AUC": 0.9966476973653752, "Accuracy": 0.9946562549910036, "Recall_Std": 0.12200391688933879, "Precision_Std": 0.045501432069008044, "AUC_Std": 0.0023963537904507673, "Accuracy_Std": 0.0010913044842563702, "F1-Score": 0.28564089324011244}}, {"trial": 64, "search_space": "{'params': {'ccp_alpha': 0.075, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.023477254541923766, "AUC": 0.9866246168503707, "Accuracy": 0.9524365260137377, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.0025802336931948556, "AUC_Std": 0.006953734366361445, "Accuracy_Std": 0.008629362397040131, "F1-Score": 0.045687952869338314}}, {"trial": 65, "search_space": "{'params': {'ccp_alpha': 0.059, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.027116833873523198, "AUC": 0.9893224400841415, "Accuracy": 0.9595878018695967, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.002171496033748109, "AUC_Std": 0.006298439596092175, "Accuracy_Std": 0.0036952533570416652, "F1-Score": 0.052583608640308685}}, {"trial": 66, "search_space": "{'params': {'ccp_alpha': 0.017, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8551136363636364, "Precision": 0.10965454278408673, "AUC": 0.9958008659993991, "Accuracy": 0.9907957719749472, "Recall_Std": 0.11396338676906333, "Precision_Std": 0.017923625871369617, "AUC_Std": 0.0030345240939758, "Accuracy_Std": 0.0009605773134119835, "F1-Score": 0.19414996122889255}}, {"trial": 67, "search_space": "{'params': {'ccp_alpha': 0.035, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8705018939393939, "Precision": 0.04528081234075364, "AUC": 0.9930596665514626, "Accuracy": 0.9747449284070574, "Recall_Std": 0.10334423740219516, "Precision_Std": 0.01204452835220484, "AUC_Std": 0.005180574092917571, "Accuracy_Std": 0.005815332060271818, "F1-Score": 0.08593364619176633}}, {"trial": 68, "search_space": "{'params': {'ccp_alpha': 0.095, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.0211485109856506, "AUC": 0.9855203877827181, "Accuracy": 0.9457862313182563, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.003636137600937856, "AUC_Std": 0.007073812045873287, "Accuracy_Std": 0.013671777345763678, "F1-Score": 0.04124225511958443}}, {"trial": 69, "search_space": "{'params': {'ccp_alpha': 0.041, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8702651515151515, "Precision": 0.033388964202805196, "AUC": 0.9919086382567069, "Accuracy": 0.9667390653745913, "Recall_Std": 0.08925157995684663, "Precision_Std": 0.006097864560130267, "AUC_Std": 0.005116125924225954, "Accuracy_Std": 0.004445997086805502, "F1-Score": 0.06426723747036478}}, {"trial": 70, "search_space": "{'params': {'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.6711647727272727, "Precision": 0.8888167184007592, "AUC": 0.9833328514216886, "Accuracy": 0.9994695550809565, "Recall_Std": 0.1218749908025473, "Precision_Std": 0.0243144883492399, "AUC_Std": 0.015751198479472976, "Accuracy_Std": 0.0001402943573615322, "F1-Score": 0.7586582977207977}}]