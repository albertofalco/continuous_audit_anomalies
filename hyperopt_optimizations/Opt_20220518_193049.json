[{"trial": 0, "search_space": "{'params': {'C': 1.015454472547284, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 42}}", "scorings": {"Recall": 0.6196428571428572, "Precision": 0.8186758893280632, "AUC": 0.8086899842581661, "Accuracy": 0.9934816187196807, "Recall_Std": 0.13156108528359642, "Precision_Std": 0.2633445557215853, "AUC_Std": 0.0671972482058229, "Accuracy_Std": 0.004609586336389242, "F1-Score": 0.6967588893788129}}, {"trial": 1, "search_space": "{'params': {'C': 1.0238117311147457, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 42}}", "scorings": {"Recall": 0.6196428571428572, "Precision": 0.8186758893280632, "AUC": 0.8086899842581661, "Accuracy": 0.9934816187196807, "Recall_Std": 0.13156108528359642, "Precision_Std": 0.2633445557215853, "AUC_Std": 0.0671972482058229, "Accuracy_Std": 0.004609586336389242, "F1-Score": 0.6967588893788129}}, {"trial": 2, "search_space": "{'params': {'C': 1.00335574650528, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 42}}", "scorings": {"Recall": 0.6196428571428572, "Precision": 0.8186758893280632, "AUC": 0.8086899842581661, "Accuracy": 0.9934816187196807, "Recall_Std": 0.13156108528359642, "Precision_Std": 0.2633445557215853, "AUC_Std": 0.0671972482058229, "Accuracy_Std": 0.004609586336389242, "F1-Score": 0.6967588893788129}}, {"trial": 3, "search_space": "{'params': {'C': 1.0270486908780039, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 42}}", "scorings": {"Recall": 0.6196428571428572, "Precision": 0.8186758893280632, "AUC": 0.8086899842581661, "Accuracy": 0.9934816187196807, "Recall_Std": 0.13156108528359642, "Precision_Std": 0.2633445557215853, "AUC_Std": 0.0671972482058229, "Accuracy_Std": 0.004609586336389242, "F1-Score": 0.6967588893788129}}, {"trial": 4, "search_space": "{'params': {'C': 1.023203377489023, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 42}}", "scorings": {"Recall": 0.6196428571428572, "Precision": 0.8186758893280632, "AUC": 0.8086899842581661, "Accuracy": 0.9934816187196807, "Recall_Std": 0.13156108528359642, "Precision_Std": 0.2633445557215853, "AUC_Std": 0.0671972482058229, "Accuracy_Std": 0.004609586336389242, "F1-Score": 0.6967588893788129}}, {"trial": 5, "search_space": "{'params': {'C': 1.0018571293259664, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 42}}", "scorings": {"Recall": 0.6196428571428572, "Precision": 0.8186758893280632, "AUC": 0.8086899842581661, "Accuracy": 0.9934816187196807, "Recall_Std": 0.13156108528359642, "Precision_Std": 0.2633445557215853, "AUC_Std": 0.0671972482058229, "Accuracy_Std": 0.004609586336389242, "F1-Score": 0.6967588893788129}}, {"trial": 6, "search_space": "{'params': {'C': 1.032406564866805, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 42}}", "scorings": {"Recall": 0.6196428571428572, "Precision": 0.8186758893280632, "AUC": 0.8086899842581661, "Accuracy": 0.9934816187196807, "Recall_Std": 0.13156108528359642, "Precision_Std": 0.2633445557215853, "AUC_Std": 0.0671972482058229, "Accuracy_Std": 0.004609586336389242, "F1-Score": 0.6967588893788129}}, {"trial": 7, "search_space": "{'params': {'C': 0.9965459334909539, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 42}}", "scorings": {"Recall": 0.6196428571428572, "Precision": 0.8186758893280632, "AUC": 0.8086899842581661, "Accuracy": 0.9934816187196807, "Recall_Std": 0.13156108528359642, "Precision_Std": 0.2633445557215853, "AUC_Std": 0.0671972482058229, "Accuracy_Std": 0.004609586336389242, "F1-Score": 0.6967588893788129}}, {"trial": 8, "search_space": "{'params': {'C': 1.0072940936320833, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 42}}", "scorings": {"Recall": 0.6196428571428572, "Precision": 0.8186758893280632, "AUC": 0.8086899842581661, "Accuracy": 0.9934816187196807, "Recall_Std": 0.13156108528359642, "Precision_Std": 0.2633445557215853, "AUC_Std": 0.0671972482058229, "Accuracy_Std": 0.004609586336389242, "F1-Score": 0.6967588893788129}}, {"trial": 9, "search_space": "{'params': {'C': 0.996071259225442, 'loss': 'squared_hinge', 'penalty': 'l2', 'random_state': 42}}", "scorings": {"Recall": 0.6196428571428572, "Precision": 0.8186758893280632, "AUC": 0.8086899842581661, "Accuracy": 0.9934816187196807, "Recall_Std": 0.13156108528359642, "Precision_Std": 0.2633445557215853, "AUC_Std": 0.0671972482058229, "Accuracy_Std": 0.004609586336389242, "F1-Score": 0.6967588893788129}}]