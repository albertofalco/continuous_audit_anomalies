[{"trial": 0, "search_space": "{'params': {'bootstrap': False, 'ccp_alpha': 0.081, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42, 'warm_start': True}}", "scorings": {"Recall": 0.8621323529411764, "Precision": 0.012907176686804267, "AUC": 0.9520720280898453, "Accuracy": 0.913909626719057, "Recall_Std": 0.053813533707001635, "Precision_Std": 0.0009797093019240047, "AUC_Std": 0.0335913221684926, "Accuracy_Std": 0.007634224708650239, "F1-Score": 0.02543122770000301}}, {"trial": 1, "search_space": "{'params': {'bootstrap': True, 'ccp_alpha': 0.03, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42, 'warm_start': False}}", "scorings": {"Recall": 0.8612132352941178, "Precision": 0.19267699317337753, "AUC": 0.9943151433798519, "Accuracy": 0.9931630648330059, "Recall_Std": 0.08296023293543975, "Precision_Std": 0.08230593091099091, "AUC_Std": 0.005470526178569358, "Accuracy_Std": 0.0047386446936523, "F1-Score": 0.3045912772757891}}, {"trial": 2, "search_space": "{'params': {'bootstrap': True, 'ccp_alpha': 0.015, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42, 'warm_start': True}}", "scorings": {"Recall": 0.8299632352941178, "Precision": 0.373102734051367, "AUC": 0.9966120676972097, "Accuracy": 0.9973673870333989, "Recall_Std": 0.11338723453098577, "Precision_Std": 0.16205407675249026, "AUC_Std": 0.002680345852987795, "Accuracy_Std": 0.0012530623747820894, "F1-Score": 0.48412159979324165}}, {"trial": 3, "search_space": "{'params': {'bootstrap': True, 'ccp_alpha': 0.04, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42, 'warm_start': False}}", "scorings": {"Recall": 0.8768382352941178, "Precision": 0.13401581179456357, "AUC": 0.9915062571389548, "Accuracy": 0.99049115913556, "Recall_Std": 0.06433823529411764, "Precision_Std": 0.050079186827333054, "AUC_Std": 0.009103079521859824, "Accuracy_Std": 0.005426097083207547, "F1-Score": 0.2286810747242785}}, {"trial": 4, "search_space": "{'params': {'bootstrap': False, 'ccp_alpha': 0.05, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42, 'warm_start': True}}", "scorings": {"Recall": 0.8474264705882353, "Precision": 0.02106929817766862, "AUC": 0.9678204086917968, "Accuracy": 0.9401571709233791, "Recall_Std": 0.054313554054022634, "Precision_Std": 0.007585607937930983, "AUC_Std": 0.022458352725668197, "Accuracy_Std": 0.02463365935072719, "F1-Score": 0.040963561238617205}}, {"trial": 5, "search_space": "{'params': {'bootstrap': True, 'ccp_alpha': 0.075, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42, 'warm_start': False}}", "scorings": {"Recall": 0.8915441176470589, "Precision": 0.04502924149680981, "AUC": 0.9820609808289864, "Accuracy": 0.9730058939096267, "Recall_Std": 0.08173431645373422, "Precision_Std": 0.013573281291543202, "AUC_Std": 0.021798438409185498, "Accuracy_Std": 0.007622080861450918, "F1-Score": 0.08529674001835055}}, {"trial": 6, "search_space": "{'params': {'bootstrap': True, 'ccp_alpha': 0.07, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42, 'warm_start': False}}", "scorings": {"Recall": 0.8759191176470589, "Precision": 0.04830111210033978, "AUC": 0.9825618839509356, "Accuracy": 0.9747740667976424, "Recall_Std": 0.09941352542601917, "Precision_Std": 0.016282149866180106, "AUC_Std": 0.02124134239373585, "Accuracy_Std": 0.007989672237091013, "F1-Score": 0.09106915673425671}}, {"trial": 7, "search_space": "{'params': {'bootstrap': False, 'ccp_alpha': 0.007, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42, 'warm_start': True}}", "scorings": {"Recall": 0.801470588235294, "Precision": 0.10822720980284006, "AUC": 0.966278118757611, "Accuracy": 0.9893713163064832, "Recall_Std": 0.05551348849463785, "Precision_Std": 0.044045945471257994, "AUC_Std": 0.02213385327902181, "Accuracy_Std": 0.004406877274547721, "F1-Score": 0.18693893673882617}}, {"trial": 8, "search_space": "{'params': {'bootstrap': True, 'ccp_alpha': 0.072, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42, 'warm_start': True}}", "scorings": {"Recall": 0.8915441176470589, "Precision": 0.04815901070611464, "AUC": 0.98214321529037, "Accuracy": 0.9746168958742633, "Recall_Std": 0.08173431645373422, "Precision_Std": 0.014806575716221645, "AUC_Std": 0.021558531424374437, "Accuracy_Std": 0.007740368787412494, "F1-Score": 0.09093429883930859}}, {"trial": 9, "search_space": "{'params': {'bootstrap': True, 'ccp_alpha': 0.033, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42, 'warm_start': False}}", "scorings": {"Recall": 0.8612132352941178, "Precision": 0.17196035663692952, "AUC": 0.9937908947589513, "Accuracy": 0.991827111984283, "Recall_Std": 0.08296023293543975, "Precision_Std": 0.07928963105316714, "AUC_Std": 0.006388857395120788, "Accuracy_Std": 0.005883947048278192, "F1-Score": 0.27652056850282486}}]