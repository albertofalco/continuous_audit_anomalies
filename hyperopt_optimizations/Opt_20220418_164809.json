[{"trial": 0, "search_space": "{'params': {'ccp_alpha': 0.002, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8005514705882353, "Precision": 0.8504464285714286, "AUC": 0.9759634476891956, "Accuracy": 0.9995284872298624, "Recall_Std": 0.08473347532349845, "Precision_Std": 0.12101014436098034, "AUC_Std": 0.013828757598289419, "Accuracy_Std": 0.0001667049385901132, "F1-Score": 0.8158448520290625}}, {"trial": 1, "search_space": "{'params': {'ccp_alpha': 0.084, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8915441176470589, "Precision": 0.042208301554963336, "AUC": 0.9816652658247323, "Accuracy": 0.9708251473477407, "Recall_Std": 0.08173431645373422, "Precision_Std": 0.013534441875653135, "AUC_Std": 0.021802863788920733, "Accuracy_Std": 0.008719334976280236, "F1-Score": 0.08015603041790653}}, {"trial": 2, "search_space": "{'params': {'ccp_alpha': 0.011, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8299632352941178, "Precision": 0.4599019607843137, "AUC": 0.9969315685396778, "Accuracy": 0.9981139489194499, "Recall_Std": 0.11338723453098577, "Precision_Std": 0.1893408799257409, "AUC_Std": 0.0020325676008120983, "Accuracy_Std": 0.0007759692596515656, "F1-Score": 0.5583295387469432}}, {"trial": 3, "search_space": "{'params': {'ccp_alpha': 0.063, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8759191176470589, "Precision": 0.05934656526795341, "AUC": 0.9863085393414139, "Accuracy": 0.9792337917485265, "Recall_Std": 0.09941352542601917, "Precision_Std": 0.02057796885492367, "AUC_Std": 0.015329702611572207, "Accuracy_Std": 0.007508176703614608, "F1-Score": 0.11046124987037595}}, {"trial": 4, "search_space": "{'params': {'ccp_alpha': 0.03, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8612132352941178, "Precision": 0.19267699317337753, "AUC": 0.9943151433798519, "Accuracy": 0.9931630648330059, "Recall_Std": 0.08296023293543975, "Precision_Std": 0.08230593091099091, "AUC_Std": 0.005470526178569358, "Accuracy_Std": 0.0047386446936523, "F1-Score": 0.3045912772757891}}, {"trial": 5, "search_space": "{'params': {'ccp_alpha': 0.073, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8915441176470589, "Precision": 0.04755825703177978, "AUC": 0.9819841805820618, "Accuracy": 0.9741846758349706, "Recall_Std": 0.08173431645373422, "Precision_Std": 0.014893313102414724, "AUC_Std": 0.021618942143452374, "Accuracy_Std": 0.008018124373681728, "F1-Score": 0.08984827818244681}}, {"trial": 6, "search_space": "{'params': {'ccp_alpha': 0.074, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8915441176470589, "Precision": 0.04511172461949394, "AUC": 0.9818544342871657, "Accuracy": 0.9730255402750492, "Recall_Std": 0.08173431645373422, "Precision_Std": 0.013696815685054205, "AUC_Std": 0.021720679182415725, "Accuracy_Std": 0.0076533878429730015, "F1-Score": 0.08543801365451661}}, {"trial": 7, "search_space": "{'params': {'ccp_alpha': 0.047, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8768382352941178, "Precision": 0.08845568783068783, "AUC": 0.9910774255756496, "Accuracy": 0.9866208251473478, "Recall_Std": 0.06433823529411764, "Precision_Std": 0.0268094404277009, "AUC_Std": 0.009476683055776975, "Accuracy_Std": 0.00494912963581079, "F1-Score": 0.1594798525325366}}, {"trial": 8, "search_space": "{'params': {'ccp_alpha': 0.003, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8005514705882353, "Precision": 0.7416274708263872, "AUC": 0.9757000162881246, "Accuracy": 0.9993516699410608, "Recall_Std": 0.08473347532349845, "Precision_Std": 0.08380737389735583, "AUC_Std": 0.01397562838834237, "Accuracy_Std": 0.00015090659622528108, "F1-Score": 0.7627335168336009}}, {"trial": 9, "search_space": "{'params': {'ccp_alpha': 0.093, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 352, 'max_features': 0.9291134341710399, 'max_samples': 0.8461053136089318, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 74, 'random_state': 42}}", "scorings": {"Recall": 0.8915441176470589, "Precision": 0.04174521498210859, "AUC": 0.9830204192396492, "Accuracy": 0.9704911591355599, "Recall_Std": 0.08173431645373422, "Precision_Std": 0.01348994939610994, "AUC_Std": 0.018124959549027795, "Accuracy_Std": 0.008736162370327953, "F1-Score": 0.07930556580521914}}]