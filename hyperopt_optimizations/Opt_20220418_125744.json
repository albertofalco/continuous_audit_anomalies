[{"trial": 0, "search_space": "{'params': {'class_weight': None, 'criterion': 'entropy', 'max_depth': 15.0, 'max_features': 0.8955339629253539, 'max_samples': 0.6581070979089769, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 3, 'random_state': 42}}", "scorings": {"Recall": 0.6796875, "Precision": 0.9037037037037037, "AUC": 0.9004180106984563, "Accuracy": 0.9994990257869836, "Recall_Std": 0.11560474618168819, "Precision_Std": 0.08097485595953867, "AUC_Std": 0.018210916006442698, "Accuracy_Std": 0.00020106246840431014, "F1-Score": 0.7730516329198436}}, {"trial": 1, "search_space": "{'params': {'class_weight': None, 'criterion': 'gini', 'max_depth': 16.0, 'max_features': 0.8748374337220912, 'max_samples': 0.6474242459540229, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 84, 'random_state': 42}}", "scorings": {"Recall": 0.7478693181818181, "Precision": 0.9811253561253561, "AUC": 0.952910939079012, "Accuracy": 0.9996561920787885, "Recall_Std": 0.027235669991719336, "Precision_Std": 0.018881362025372602, "AUC_Std": 0.037110508397164475, "Accuracy_Std": 1.7012246963111544e-05, "F1-Score": 0.8481482983267103}}, {"trial": 2, "search_space": "{'params': {'class_weight': None, 'criterion': 'gini', 'max_depth': 7.0, 'max_features': 0.6558947661457027, 'max_samples': 0.1662949229054717, 'min_samples_leaf': 1, 'min_samples_split': 1, 'n_estimators': 12, 'random_state': 42}}", "scorings": {"Recall": NaN, "Precision": NaN, "AUC": NaN, "Accuracy": NaN, "Recall_Std": NaN, "Precision_Std": NaN, "AUC_Std": NaN, "Accuracy_Std": NaN, "F1-Score": NaN}}, {"trial": 3, "search_space": "{'params': {'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 28.0, 'max_features': 0.6332080719932267, 'max_samples': 0.2909954052940017, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 63, 'random_state': 42}}", "scorings": {"Recall": 0.5258049242424243, "Precision": 0.984375, "AUC": 0.949374410588615, "Accuracy": 0.9993811468225202, "Recall_Std": 0.1367172639464036, "Precision_Std": 0.027063293868263706, "AUC_Std": 0.01759064419171164, "Accuracy_Std": 0.0001787119057560463, "F1-Score": 0.6762882164359997}}, {"trial": 4, "search_space": "{'params': {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 4.0, 'max_features': 0.35862068786791046, 'max_samples': 0.18698018110930825, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 31, 'random_state': 42}}", "scorings": {"Recall": 0.7556818181818181, "Precision": 0.19148212365805628, "AUC": 0.9870908315853276, "Accuracy": 0.9955894318749098, "Recall_Std": 0.09824782082835558, "Precision_Std": 0.013478965751944983, "AUC_Std": 0.009201078392346195, "Accuracy_Std": 0.0002783981304870205, "F1-Score": 0.30519282651635593}}]